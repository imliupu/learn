{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writen by liupu -- 2019.4.13\n",
    "# Need to install numpy, sklearn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "data=iris.data      #data_x\n",
    "target=iris.target  #data_y\n",
    "labels=iris.feature_names #feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "(150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "(150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(data.shape)\n",
    "print(data[:10])\n",
    "print(target.shape)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.append(np.append(target[:40], target[50:90]), target[100:140])\n",
    "train_x = np.append(np.append(data[:40,], data[50:90,], axis=0), data[100:140,], axis=0)\n",
    "test_y = np.append(np.append(target[40:50], target[90:100]), target[140:150])\n",
    "test_x = np.append(np.append(data[40:50], data[90:100], axis=0), data[140:150], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (120,)\n",
      "(30, 4) (30,)\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self):\n",
    "        self._w = None                 # _w = [ feature_num, bias ]\n",
    "        self._x = None\n",
    "        self._y = None\n",
    "        self._feature_num = 0\n",
    "    \n",
    "    def softmax(x):\n",
    "        return \n",
    "    \n",
    "    def fit(self, x, y, optimizer=\"square\", learning_rate=0.001, epoch=1, log=True):\n",
    "        assert len(x.shape) == 2\n",
    "        assert len(y.shape) == 1\n",
    "        assert x.shape[0] == y.shape[0]\n",
    "        self._feature_num = x.shape[1]\n",
    "        if self._w == None:\n",
    "            self._w = np.random.normal(0.1, 1, size=self._feature_num+1)    # _w = [ feature_num, bias ], ^y = Xw\n",
    "        self._x = np.append(x, np.tile(1, [x.shape[0],1]), axis=1)\n",
    "        self._y = y\n",
    "        if optimizer == \"square\":\n",
    "            self._w = np.matmul(np.linalg.pinv(self._x), self._y)\n",
    "        elif optimizer == \"sgd\":\n",
    "            if log == True:\n",
    "                print(\"Log is working on...\")\n",
    "                print(\"The learning_rate is now %f. Start...\"%learning_rate)\n",
    "            for j in range(epoch):\n",
    "                print(\"********************* Epoch %d **********************\"%j)\n",
    "                for i, item in enumerate(self._x):\n",
    "                    loss = 1/2*(self._y[i]-np.matmul(item.T, self._w))**2\n",
    "                    gradient = -1*item*(self._y[i]-np.matmul(item.T, self._w))\n",
    "                    self._w -= learning_rate * gradient\n",
    "                    if i:\n",
    "                        print(\"Iter : %d, Loss : %f\"%(i+1,loss))\n",
    "            \n",
    "    \n",
    "    def predict(self, x):\n",
    "        assert len(x.shape) == 2\n",
    "        assert self._feature_num == x.shape[1]\n",
    "        expand_x = np.append(x, np.tile(1, [x.shape[0],1]), axis=1)\n",
    "        return np.matmul(expand_x, self._w)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log is working on...\n",
      "The learning_rate is now 0.001000. Start...\n",
      "********************* Epoch 0 **********************\n",
      "Iter : 2, Loss : 3.064480\n",
      "Iter : 3, Loss : 3.017469\n",
      "Iter : 4, Loss : 3.352576\n",
      "Iter : 5, Loss : 3.075749\n",
      "Iter : 6, Loss : 4.170618\n",
      "Iter : 7, Loss : 2.924614\n",
      "Iter : 8, Loss : 2.361111\n",
      "Iter : 9, Loss : 2.018982\n",
      "Iter : 10, Loss : 1.672263\n",
      "Iter : 11, Loss : 1.795022\n",
      "Iter : 12, Loss : 2.156456\n",
      "Iter : 13, Loss : 1.120772\n",
      "Iter : 14, Loss : 0.929126\n",
      "Iter : 15, Loss : 0.721578\n",
      "Iter : 16, Loss : 1.781896\n",
      "Iter : 17, Loss : 1.126319\n",
      "Iter : 18, Loss : 1.038265\n",
      "Iter : 19, Loss : 1.145986\n",
      "Iter : 20, Loss : 1.201195\n",
      "Iter : 21, Loss : 0.815442\n",
      "Iter : 22, Loss : 1.087776\n",
      "Iter : 23, Loss : 0.430728\n",
      "Iter : 24, Loss : 1.162567\n",
      "Iter : 25, Loss : 1.328444\n",
      "Iter : 26, Loss : 0.459840\n",
      "Iter : 27, Loss : 0.792661\n",
      "Iter : 28, Loss : 0.348324\n",
      "Iter : 29, Loss : 0.212191\n",
      "Iter : 30, Loss : 0.580098\n",
      "Iter : 31, Loss : 0.440116\n",
      "Iter : 32, Loss : 0.251676\n",
      "Iter : 33, Loss : 0.315960\n",
      "Iter : 34, Loss : 0.170620\n",
      "Iter : 35, Loss : 0.208299\n",
      "Iter : 36, Loss : 0.035847\n",
      "Iter : 37, Loss : 0.011600\n",
      "Iter : 38, Loss : 0.172930\n",
      "Iter : 39, Loss : 0.214243\n",
      "Iter : 40, Loss : 0.144618\n",
      "Iter : 41, Loss : 3.767874\n",
      "Iter : 42, Loss : 3.902468\n",
      "Iter : 43, Loss : 3.453713\n",
      "Iter : 44, Loss : 2.036575\n",
      "Iter : 45, Loss : 2.309965\n",
      "Iter : 46, Loss : 2.641487\n",
      "Iter : 47, Loss : 2.708917\n",
      "Iter : 48, Loss : 0.510698\n",
      "Iter : 49, Loss : 0.950301\n",
      "Iter : 50, Loss : 1.431773\n",
      "Iter : 51, Loss : 0.328583\n",
      "Iter : 52, Loss : 1.099225\n",
      "Iter : 53, Loss : 0.099743\n",
      "Iter : 54, Loss : 1.237048\n",
      "Iter : 55, Loss : 0.254039\n",
      "Iter : 56, Loss : 0.240910\n",
      "Iter : 57, Loss : 1.440140\n",
      "Iter : 58, Loss : 0.139386\n",
      "Iter : 59, Loss : 0.351995\n",
      "Iter : 60, Loss : 0.102365\n",
      "Iter : 61, Loss : 1.654831\n",
      "Iter : 62, Loss : 0.026945\n",
      "Iter : 63, Loss : 0.485157\n",
      "Iter : 64, Loss : 0.259209\n",
      "Iter : 65, Loss : 0.011141\n",
      "Iter : 66, Loss : 0.014466\n",
      "Iter : 67, Loss : 0.046571\n",
      "Iter : 68, Loss : 0.369575\n",
      "Iter : 69, Loss : 0.275020\n",
      "Iter : 70, Loss : 0.108928\n",
      "Iter : 71, Loss : 0.000978\n",
      "Iter : 72, Loss : 0.009143\n",
      "Iter : 73, Loss : 0.000802\n",
      "Iter : 74, Loss : 0.858484\n",
      "Iter : 75, Loss : 0.701241\n",
      "Iter : 76, Loss : 0.289722\n",
      "Iter : 77, Loss : 0.005625\n",
      "Iter : 78, Loss : 0.016288\n",
      "Iter : 79, Loss : 0.062812\n",
      "Iter : 80, Loss : 0.022185\n",
      "Iter : 81, Loss : 1.123992\n",
      "Iter : 82, Loss : 0.064173\n",
      "Iter : 83, Loss : 0.005835\n",
      "Iter : 84, Loss : 0.039264\n",
      "Iter : 85, Loss : 0.187219\n",
      "Iter : 86, Loss : 0.016083\n",
      "Iter : 87, Loss : 0.049015\n",
      "Iter : 88, Loss : 0.008577\n",
      "Iter : 89, Loss : 0.005467\n",
      "Iter : 90, Loss : 0.153756\n",
      "Iter : 91, Loss : 0.033039\n",
      "Iter : 92, Loss : 0.013747\n",
      "Iter : 93, Loss : 0.005498\n",
      "Iter : 94, Loss : 0.035959\n",
      "Iter : 95, Loss : 0.211256\n",
      "Iter : 96, Loss : 0.027491\n",
      "Iter : 97, Loss : 0.013373\n",
      "Iter : 98, Loss : 0.051513\n",
      "Iter : 99, Loss : 0.035513\n",
      "Iter : 100, Loss : 0.190676\n",
      "Iter : 101, Loss : 0.005773\n",
      "Iter : 102, Loss : 0.031396\n",
      "Iter : 103, Loss : 0.007601\n",
      "Iter : 104, Loss : 0.174625\n",
      "Iter : 105, Loss : 0.016268\n",
      "Iter : 106, Loss : 0.046445\n",
      "Iter : 107, Loss : 0.129291\n",
      "Iter : 108, Loss : 0.029910\n",
      "Iter : 109, Loss : 0.052829\n",
      "Iter : 110, Loss : 0.197751\n",
      "Iter : 111, Loss : 0.038842\n",
      "Iter : 112, Loss : 0.007102\n",
      "Iter : 113, Loss : 0.113629\n",
      "Iter : 114, Loss : 0.126114\n",
      "Iter : 115, Loss : 0.000566\n",
      "Iter : 116, Loss : 0.008560\n",
      "Iter : 117, Loss : 0.391848\n",
      "Iter : 118, Loss : 0.001590\n",
      "Iter : 119, Loss : 0.025886\n",
      "Iter : 120, Loss : 0.025379\n",
      "********************* Epoch 1 **********************\n",
      "Iter : 2, Loss : 1.109300\n",
      "Iter : 3, Loss : 0.841965\n",
      "Iter : 4, Loss : 0.508880\n",
      "Iter : 5, Loss : 0.835459\n",
      "Iter : 6, Loss : 0.580315\n",
      "Iter : 7, Loss : 0.329076\n",
      "Iter : 8, Loss : 0.630466\n",
      "Iter : 9, Loss : 0.307327\n",
      "Iter : 10, Loss : 0.637257\n",
      "Iter : 11, Loss : 0.803131\n",
      "Iter : 12, Loss : 0.240085\n",
      "Iter : 13, Loss : 0.544578\n",
      "Iter : 14, Loss : 0.370879\n",
      "Iter : 15, Loss : 1.325607\n",
      "Iter : 16, Loss : 0.407455\n",
      "Iter : 17, Loss : 0.439329\n",
      "Iter : 18, Loss : 0.288969\n",
      "Iter : 19, Loss : 0.361090\n",
      "Iter : 20, Loss : 0.128323\n",
      "Iter : 21, Loss : 0.279769\n",
      "Iter : 22, Loss : 0.079371\n",
      "Iter : 23, Loss : 0.206235\n",
      "Iter : 24, Loss : 0.022606\n",
      "Iter : 25, Loss : 0.000002\n",
      "Iter : 26, Loss : 0.158301\n",
      "Iter : 27, Loss : 0.030632\n",
      "Iter : 28, Loss : 0.194832\n",
      "Iter : 29, Loss : 0.260618\n",
      "Iter : 30, Loss : 0.016125\n",
      "Iter : 31, Loss : 0.040164\n",
      "Iter : 32, Loss : 0.162085\n",
      "Iter : 33, Loss : 0.085744\n",
      "Iter : 34, Loss : 0.182009\n",
      "Iter : 35, Loss : 0.071334\n",
      "Iter : 36, Loss : 0.235791\n",
      "Iter : 37, Loss : 0.362558\n",
      "Iter : 38, Loss : 0.049115\n",
      "Iter : 39, Loss : 0.008618\n",
      "Iter : 40, Loss : 0.057161\n",
      "Iter : 41, Loss : 0.675161\n",
      "Iter : 42, Loss : 1.011403\n",
      "Iter : 43, Loss : 0.798644\n",
      "Iter : 44, Loss : 0.504269\n",
      "Iter : 45, Loss : 0.535531\n",
      "Iter : 46, Loss : 0.894671\n",
      "Iter : 47, Loss : 0.922114\n",
      "Iter : 48, Loss : 0.065992\n",
      "Iter : 49, Loss : 0.139161\n",
      "Iter : 50, Loss : 0.530732\n",
      "Iter : 51, Loss : 0.029153\n",
      "Iter : 52, Loss : 0.342517\n",
      "Iter : 53, Loss : 0.009832\n",
      "Iter : 54, Loss : 0.446730\n",
      "Iter : 55, Loss : 0.030679\n",
      "Iter : 56, Loss : 0.012611\n",
      "Iter : 57, Loss : 0.727973\n",
      "Iter : 58, Loss : 0.006412\n",
      "Iter : 59, Loss : 0.072030\n",
      "Iter : 60, Loss : 0.005122\n",
      "Iter : 61, Loss : 0.984866\n",
      "Iter : 62, Loss : 0.003456\n",
      "Iter : 63, Loss : 0.181880\n",
      "Iter : 64, Loss : 0.080207\n",
      "Iter : 65, Loss : 0.006945\n",
      "Iter : 66, Loss : 0.003640\n",
      "Iter : 67, Loss : 0.000596\n",
      "Iter : 68, Loss : 0.175211\n",
      "Iter : 69, Loss : 0.139628\n",
      "Iter : 70, Loss : 0.175576\n",
      "Iter : 71, Loss : 0.005798\n",
      "Iter : 72, Loss : 0.036194\n",
      "Iter : 73, Loss : 0.004321\n",
      "Iter : 74, Loss : 0.598355\n",
      "Iter : 75, Loss : 0.528875\n",
      "Iter : 76, Loss : 0.201777\n",
      "Iter : 77, Loss : 0.000206\n",
      "Iter : 78, Loss : 0.047141\n",
      "Iter : 79, Loss : 0.036127\n",
      "Iter : 80, Loss : 0.006752\n",
      "Iter : 81, Loss : 0.833880\n",
      "Iter : 82, Loss : 0.022277\n",
      "Iter : 83, Loss : 0.001011\n",
      "Iter : 84, Loss : 0.010959\n",
      "Iter : 85, Loss : 0.113074\n",
      "Iter : 86, Loss : 0.000697\n",
      "Iter : 87, Loss : 0.027302\n",
      "Iter : 88, Loss : 0.027843\n",
      "Iter : 89, Loss : 0.020360\n",
      "Iter : 90, Loss : 0.118691\n",
      "Iter : 91, Loss : 0.039870\n",
      "Iter : 92, Loss : 0.024322\n",
      "Iter : 93, Loss : 0.011027\n",
      "Iter : 94, Loss : 0.021550\n",
      "Iter : 95, Loss : 0.175358\n",
      "Iter : 96, Loss : 0.021340\n",
      "Iter : 97, Loss : 0.018347\n",
      "Iter : 98, Loss : 0.041268\n",
      "Iter : 99, Loss : 0.014999\n",
      "Iter : 100, Loss : 0.207367\n",
      "Iter : 101, Loss : 0.004317\n",
      "Iter : 102, Loss : 0.026937\n",
      "Iter : 103, Loss : 0.014888\n",
      "Iter : 104, Loss : 0.168901\n",
      "Iter : 105, Loss : 0.015610\n",
      "Iter : 106, Loss : 0.046441\n",
      "Iter : 107, Loss : 0.121381\n",
      "Iter : 108, Loss : 0.026404\n",
      "Iter : 109, Loss : 0.043272\n",
      "Iter : 110, Loss : 0.192918\n",
      "Iter : 111, Loss : 0.044429\n",
      "Iter : 112, Loss : 0.004731\n",
      "Iter : 113, Loss : 0.098860\n",
      "Iter : 114, Loss : 0.119722\n",
      "Iter : 115, Loss : 0.000027\n",
      "Iter : 116, Loss : 0.009731\n",
      "Iter : 117, Loss : 0.382750\n",
      "Iter : 118, Loss : 0.001726\n",
      "Iter : 119, Loss : 0.021067\n",
      "Iter : 120, Loss : 0.022547\n",
      "********************* Epoch 2 **********************\n",
      "Iter : 2, Loss : 0.832609\n",
      "Iter : 3, Loss : 0.602743\n",
      "Iter : 4, Loss : 0.347458\n",
      "Iter : 5, Loss : 0.591218\n",
      "Iter : 6, Loss : 0.387330\n",
      "Iter : 7, Loss : 0.207026\n",
      "Iter : 8, Loss : 0.455326\n",
      "Iter : 9, Loss : 0.210607\n",
      "Iter : 10, Loss : 0.482444\n",
      "Iter : 11, Loss : 0.600856\n",
      "Iter : 12, Loss : 0.155922\n",
      "Iter : 13, Loss : 0.418096\n",
      "Iter : 14, Loss : 0.266144\n",
      "Iter : 15, Loss : 1.045377\n",
      "Iter : 16, Loss : 0.274268\n",
      "Iter : 17, Loss : 0.315636\n",
      "Iter : 18, Loss : 0.207928\n",
      "Iter : 19, Loss : 0.271802\n",
      "Iter : 20, Loss : 0.078963\n",
      "Iter : 21, Loss : 0.218071\n",
      "Iter : 22, Loss : 0.046128\n",
      "Iter : 23, Loss : 0.138911\n",
      "Iter : 24, Loss : 0.011694\n",
      "Iter : 25, Loss : 0.001324\n",
      "Iter : 26, Loss : 0.126783\n",
      "Iter : 27, Loss : 0.016998\n",
      "Iter : 28, Loss : 0.149573\n",
      "Iter : 29, Loss : 0.208053\n",
      "Iter : 30, Loss : 0.008294\n",
      "Iter : 31, Loss : 0.027906\n",
      "Iter : 32, Loss : 0.129434\n",
      "Iter : 33, Loss : 0.054454\n",
      "Iter : 34, Loss : 0.132315\n",
      "Iter : 35, Loss : 0.056152\n",
      "Iter : 36, Loss : 0.194933\n",
      "Iter : 37, Loss : 0.308034\n",
      "Iter : 38, Loss : 0.032564\n",
      "Iter : 39, Loss : 0.004273\n",
      "Iter : 40, Loss : 0.043831\n",
      "Iter : 41, Loss : 0.488573\n",
      "Iter : 42, Loss : 0.802499\n",
      "Iter : 43, Loss : 0.604123\n",
      "Iter : 44, Loss : 0.380386\n",
      "Iter : 45, Loss : 0.402111\n",
      "Iter : 46, Loss : 0.732843\n",
      "Iter : 47, Loss : 0.772014\n",
      "Iter : 48, Loss : 0.045821\n",
      "Iter : 49, Loss : 0.092557\n",
      "Iter : 50, Loss : 0.449692\n",
      "Iter : 51, Loss : 0.014726\n",
      "Iter : 52, Loss : 0.284948\n",
      "Iter : 53, Loss : 0.021502\n",
      "Iter : 54, Loss : 0.367891\n",
      "Iter : 55, Loss : 0.023776\n",
      "Iter : 56, Loss : 0.006239\n",
      "Iter : 57, Loss : 0.641574\n",
      "Iter : 58, Loss : 0.002584\n",
      "Iter : 59, Loss : 0.044621\n",
      "Iter : 60, Loss : 0.002111\n",
      "Iter : 61, Loss : 0.888866\n",
      "Iter : 62, Loss : 0.005388\n",
      "Iter : 63, Loss : 0.139070\n",
      "Iter : 64, Loss : 0.062535\n",
      "Iter : 65, Loss : 0.009061\n",
      "Iter : 66, Loss : 0.005110\n",
      "Iter : 67, Loss : 0.000003\n",
      "Iter : 68, Loss : 0.148465\n",
      "Iter : 69, Loss : 0.123506\n",
      "Iter : 70, Loss : 0.166026\n",
      "Iter : 71, Loss : 0.007243\n",
      "Iter : 72, Loss : 0.037431\n",
      "Iter : 73, Loss : 0.004601\n",
      "Iter : 74, Loss : 0.526527\n",
      "Iter : 75, Loss : 0.494421\n",
      "Iter : 76, Loss : 0.196696\n",
      "Iter : 77, Loss : 0.000439\n",
      "Iter : 78, Loss : 0.054905\n",
      "Iter : 79, Loss : 0.036029\n",
      "Iter : 80, Loss : 0.005191\n",
      "Iter : 81, Loss : 0.714426\n",
      "Iter : 82, Loss : 0.011310\n",
      "Iter : 83, Loss : 0.005414\n",
      "Iter : 84, Loss : 0.004423\n",
      "Iter : 85, Loss : 0.086184\n",
      "Iter : 86, Loss : 0.000331\n",
      "Iter : 87, Loss : 0.020080\n",
      "Iter : 88, Loss : 0.038931\n",
      "Iter : 89, Loss : 0.030364\n",
      "Iter : 90, Loss : 0.109188\n",
      "Iter : 91, Loss : 0.037744\n",
      "Iter : 92, Loss : 0.028867\n",
      "Iter : 93, Loss : 0.012744\n",
      "Iter : 94, Loss : 0.015584\n",
      "Iter : 95, Loss : 0.158165\n",
      "Iter : 96, Loss : 0.020434\n",
      "Iter : 97, Loss : 0.019452\n",
      "Iter : 98, Loss : 0.038746\n",
      "Iter : 99, Loss : 0.006260\n",
      "Iter : 100, Loss : 0.214185\n",
      "Iter : 101, Loss : 0.004317\n",
      "Iter : 102, Loss : 0.025430\n",
      "Iter : 103, Loss : 0.020404\n",
      "Iter : 104, Loss : 0.159368\n",
      "Iter : 105, Loss : 0.016508\n",
      "Iter : 106, Loss : 0.043968\n",
      "Iter : 107, Loss : 0.111955\n",
      "Iter : 108, Loss : 0.022430\n",
      "Iter : 109, Loss : 0.037431\n",
      "Iter : 110, Loss : 0.185200\n",
      "Iter : 111, Loss : 0.047686\n",
      "Iter : 112, Loss : 0.002726\n",
      "Iter : 113, Loss : 0.088610\n",
      "Iter : 114, Loss : 0.112851\n",
      "Iter : 115, Loss : 0.000071\n",
      "Iter : 116, Loss : 0.010264\n",
      "Iter : 117, Loss : 0.376601\n",
      "Iter : 118, Loss : 0.001976\n",
      "Iter : 119, Loss : 0.017061\n",
      "Iter : 120, Loss : 0.019870\n",
      "********************* Epoch 3 **********************\n",
      "Iter : 2, Loss : 0.627824\n",
      "Iter : 3, Loss : 0.430460\n",
      "Iter : 4, Loss : 0.234138\n",
      "Iter : 5, Loss : 0.416585\n",
      "Iter : 6, Loss : 0.253774\n",
      "Iter : 7, Loss : 0.125406\n",
      "Iter : 8, Loss : 0.328540\n",
      "Iter : 9, Loss : 0.142528\n",
      "Iter : 10, Loss : 0.367292\n",
      "Iter : 11, Loss : 0.451686\n",
      "Iter : 12, Loss : 0.098535\n",
      "Iter : 13, Loss : 0.323290\n",
      "Iter : 14, Loss : 0.190662\n",
      "Iter : 15, Loss : 0.833077\n",
      "Iter : 16, Loss : 0.181883\n",
      "Iter : 17, Loss : 0.226563\n",
      "Iter : 18, Loss : 0.149408\n",
      "Iter : 19, Loss : 0.205649\n",
      "Iter : 20, Loss : 0.046412\n",
      "Iter : 21, Loss : 0.171359\n",
      "Iter : 22, Loss : 0.024935\n",
      "Iter : 23, Loss : 0.092232\n",
      "Iter : 24, Loss : 0.005191\n",
      "Iter : 25, Loss : 0.004694\n",
      "Iter : 26, Loss : 0.102478\n",
      "Iter : 27, Loss : 0.008526\n",
      "Iter : 28, Loss : 0.115694\n",
      "Iter : 29, Loss : 0.167858\n",
      "Iter : 30, Loss : 0.003651\n",
      "Iter : 31, Loss : 0.019175\n",
      "Iter : 32, Loss : 0.104419\n",
      "Iter : 33, Loss : 0.033506\n",
      "Iter : 34, Loss : 0.096412\n",
      "Iter : 35, Loss : 0.044565\n",
      "Iter : 36, Loss : 0.163096\n",
      "Iter : 37, Loss : 0.264943\n",
      "Iter : 38, Loss : 0.021181\n",
      "Iter : 39, Loss : 0.001761\n",
      "Iter : 40, Loss : 0.033843\n",
      "Iter : 41, Loss : 0.354934\n",
      "Iter : 42, Loss : 0.645013\n",
      "Iter : 43, Loss : 0.461378\n",
      "Iter : 44, Loss : 0.289624\n",
      "Iter : 45, Loss : 0.304610\n",
      "Iter : 46, Loss : 0.608714\n",
      "Iter : 47, Loss : 0.655392\n",
      "Iter : 48, Loss : 0.031686\n",
      "Iter : 49, Loss : 0.060740\n",
      "Iter : 50, Loss : 0.386278\n",
      "Iter : 51, Loss : 0.006396\n",
      "Iter : 52, Loss : 0.240363\n",
      "Iter : 53, Loss : 0.034645\n",
      "Iter : 54, Loss : 0.307253\n",
      "Iter : 55, Loss : 0.018618\n",
      "Iter : 56, Loss : 0.002607\n",
      "Iter : 57, Loss : 0.572387\n",
      "Iter : 58, Loss : 0.000694\n",
      "Iter : 59, Loss : 0.026690\n",
      "Iter : 60, Loss : 0.000600\n",
      "Iter : 61, Loss : 0.810784\n",
      "Iter : 62, Loss : 0.007324\n",
      "Iter : 63, Loss : 0.107519\n",
      "Iter : 64, Loss : 0.049357\n",
      "Iter : 65, Loss : 0.011030\n",
      "Iter : 66, Loss : 0.006520\n",
      "Iter : 67, Loss : 0.000552\n",
      "Iter : 68, Loss : 0.127573\n",
      "Iter : 69, Loss : 0.110563\n",
      "Iter : 70, Loss : 0.157989\n",
      "Iter : 71, Loss : 0.008560\n",
      "Iter : 72, Loss : 0.038415\n",
      "Iter : 73, Loss : 0.004837\n",
      "Iter : 74, Loss : 0.469181\n",
      "Iter : 75, Loss : 0.465573\n",
      "Iter : 76, Loss : 0.192074\n",
      "Iter : 77, Loss : 0.000699\n",
      "Iter : 78, Loss : 0.061703\n",
      "Iter : 79, Loss : 0.035859\n",
      "Iter : 80, Loss : 0.004035\n",
      "Iter : 81, Loss : 0.619489\n",
      "Iter : 82, Loss : 0.004877\n",
      "Iter : 83, Loss : 0.011853\n",
      "Iter : 84, Loss : 0.001162\n",
      "Iter : 85, Loss : 0.066165\n",
      "Iter : 86, Loss : 0.003099\n",
      "Iter : 87, Loss : 0.014751\n",
      "Iter : 88, Loss : 0.049631\n",
      "Iter : 89, Loss : 0.040274\n",
      "Iter : 90, Loss : 0.101183\n",
      "Iter : 91, Loss : 0.036066\n",
      "Iter : 92, Loss : 0.032989\n",
      "Iter : 93, Loss : 0.014298\n",
      "Iter : 94, Loss : 0.011264\n",
      "Iter : 95, Loss : 0.144017\n",
      "Iter : 96, Loss : 0.019596\n",
      "Iter : 97, Loss : 0.020405\n",
      "Iter : 98, Loss : 0.036620\n",
      "Iter : 99, Loss : 0.001844\n",
      "Iter : 100, Loss : 0.219692\n",
      "Iter : 101, Loss : 0.004295\n",
      "Iter : 102, Loss : 0.024092\n",
      "Iter : 103, Loss : 0.025602\n",
      "Iter : 104, Loss : 0.151449\n",
      "Iter : 105, Loss : 0.017219\n",
      "Iter : 106, Loss : 0.041882\n",
      "Iter : 107, Loss : 0.104274\n",
      "Iter : 108, Loss : 0.019365\n",
      "Iter : 109, Loss : 0.032795\n",
      "Iter : 110, Loss : 0.178523\n",
      "Iter : 111, Loss : 0.050370\n",
      "Iter : 112, Loss : 0.001466\n",
      "Iter : 113, Loss : 0.080291\n",
      "Iter : 114, Loss : 0.107129\n",
      "Iter : 115, Loss : 0.000391\n",
      "Iter : 116, Loss : 0.010684\n",
      "Iter : 117, Loss : 0.370673\n",
      "Iter : 118, Loss : 0.002187\n",
      "Iter : 119, Loss : 0.014046\n",
      "Iter : 120, Loss : 0.017736\n",
      "********************* Epoch 4 **********************\n",
      "Iter : 2, Loss : 0.476844\n",
      "Iter : 3, Loss : 0.307305\n",
      "Iter : 4, Loss : 0.155685\n",
      "Iter : 5, Loss : 0.292776\n",
      "Iter : 6, Loss : 0.162913\n",
      "Iter : 7, Loss : 0.072349\n",
      "Iter : 8, Loss : 0.237386\n",
      "Iter : 9, Loss : 0.095251\n",
      "Iter : 10, Loss : 0.281933\n",
      "Iter : 11, Loss : 0.342070\n",
      "Iter : 12, Loss : 0.060268\n",
      "Iter : 13, Loss : 0.252398\n",
      "Iter : 14, Loss : 0.136616\n",
      "Iter : 15, Loss : 0.672214\n",
      "Iter : 16, Loss : 0.118717\n",
      "Iter : 17, Loss : 0.162828\n",
      "Iter : 18, Loss : 0.107445\n",
      "Iter : 19, Loss : 0.156837\n",
      "Iter : 20, Loss : 0.025651\n",
      "Iter : 21, Loss : 0.136096\n",
      "Iter : 22, Loss : 0.012094\n",
      "Iter : 23, Loss : 0.060285\n",
      "Iter : 24, Loss : 0.001722\n",
      "Iter : 25, Loss : 0.009140\n",
      "Iter : 26, Loss : 0.083787\n",
      "Iter : 27, Loss : 0.003625\n",
      "Iter : 28, Loss : 0.090389\n",
      "Iter : 29, Loss : 0.137127\n",
      "Iter : 30, Loss : 0.001190\n",
      "Iter : 31, Loss : 0.013042\n",
      "Iter : 32, Loss : 0.085279\n",
      "Iter : 33, Loss : 0.019810\n",
      "Iter : 34, Loss : 0.070572\n",
      "Iter : 35, Loss : 0.035746\n",
      "Iter : 36, Loss : 0.138254\n",
      "Iter : 37, Loss : 0.230830\n",
      "Iter : 38, Loss : 0.013479\n",
      "Iter : 39, Loss : 0.000491\n",
      "Iter : 40, Loss : 0.026380\n",
      "Iter : 41, Loss : 0.258826\n",
      "Iter : 42, Loss : 0.525209\n",
      "Iter : 43, Loss : 0.355906\n",
      "Iter : 44, Loss : 0.222696\n",
      "Iter : 45, Loss : 0.232904\n",
      "Iter : 46, Loss : 0.512620\n",
      "Iter : 47, Loss : 0.563893\n",
      "Iter : 48, Loss : 0.021776\n",
      "Iter : 49, Loss : 0.039148\n",
      "Iter : 50, Loss : 0.336172\n",
      "Iter : 51, Loss : 0.002050\n",
      "Iter : 52, Loss : 0.205489\n",
      "Iter : 53, Loss : 0.047952\n",
      "Iter : 54, Loss : 0.260187\n",
      "Iter : 55, Loss : 0.014723\n",
      "Iter : 56, Loss : 0.000761\n",
      "Iter : 57, Loss : 0.516488\n",
      "Iter : 58, Loss : 0.000034\n",
      "Iter : 59, Loss : 0.015198\n",
      "Iter : 60, Loss : 0.000042\n",
      "Iter : 61, Loss : 0.746739\n",
      "Iter : 62, Loss : 0.009167\n",
      "Iter : 63, Loss : 0.084124\n",
      "Iter : 64, Loss : 0.039454\n",
      "Iter : 65, Loss : 0.012814\n",
      "Iter : 66, Loss : 0.007828\n",
      "Iter : 67, Loss : 0.001735\n",
      "Iter : 68, Loss : 0.111114\n",
      "Iter : 69, Loss : 0.100081\n",
      "Iter : 70, Loss : 0.151208\n",
      "Iter : 71, Loss : 0.009733\n",
      "Iter : 72, Loss : 0.039190\n",
      "Iter : 73, Loss : 0.005037\n",
      "Iter : 74, Loss : 0.423056\n",
      "Iter : 75, Loss : 0.441229\n",
      "Iter : 76, Loss : 0.187820\n",
      "Iter : 77, Loss : 0.000961\n",
      "Iter : 78, Loss : 0.067534\n",
      "Iter : 79, Loss : 0.035621\n",
      "Iter : 80, Loss : 0.003173\n",
      "Iter : 81, Loss : 0.543420\n",
      "Iter : 82, Loss : 0.001500\n",
      "Iter : 83, Loss : 0.019236\n",
      "Iter : 84, Loss : 0.000043\n",
      "Iter : 85, Loss : 0.051185\n",
      "Iter : 86, Loss : 0.007597\n",
      "Iter : 87, Loss : 0.010811\n",
      "Iter : 88, Loss : 0.059562\n",
      "Iter : 89, Loss : 0.049631\n",
      "Iter : 90, Loss : 0.094380\n",
      "Iter : 91, Loss : 0.034752\n",
      "Iter : 92, Loss : 0.036663\n",
      "Iter : 93, Loss : 0.015687\n",
      "Iter : 94, Loss : 0.008132\n",
      "Iter : 95, Loss : 0.132284\n",
      "Iter : 96, Loss : 0.018816\n",
      "Iter : 97, Loss : 0.021223\n",
      "Iter : 98, Loss : 0.034813\n",
      "Iter : 99, Loss : 0.000165\n",
      "Iter : 100, Loss : 0.224059\n",
      "Iter : 101, Loss : 0.004254\n",
      "Iter : 102, Loss : 0.022893\n",
      "Iter : 103, Loss : 0.030300\n",
      "Iter : 104, Loss : 0.144839\n",
      "Iter : 105, Loss : 0.017763\n",
      "Iter : 106, Loss : 0.040113\n",
      "Iter : 107, Loss : 0.097986\n",
      "Iter : 108, Loss : 0.016990\n",
      "Iter : 109, Loss : 0.029088\n",
      "Iter : 110, Loss : 0.172707\n",
      "Iter : 111, Loss : 0.052535\n",
      "Iter : 112, Loss : 0.000708\n",
      "Iter : 113, Loss : 0.073491\n",
      "Iter : 114, Loss : 0.102341\n",
      "Iter : 115, Loss : 0.000857\n",
      "Iter : 116, Loss : 0.011003\n",
      "Iter : 117, Loss : 0.364943\n",
      "Iter : 118, Loss : 0.002359\n",
      "Iter : 119, Loss : 0.011764\n",
      "Iter : 120, Loss : 0.016024\n"
     ]
    }
   ],
   "source": [
    "linear = Linear()\n",
    "linear.fit(x=train_x, y=train_y, optimizer=\"sgd\", epoch=5)\n",
    "y = linear.predict(test_x)\n",
    "yy = linear.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.78485317 -0.81609577 -0.48272682 -0.34425617 -0.24859888 -0.73234928\n",
      " -0.61459807 -0.57236835 -0.88510999 -0.85985246  1.39504518  1.34838703\n",
      "  0.86310966  0.74667257  1.28048724  1.23393876  1.27220189  0.93969628\n",
      "  0.59618146  1.16359936  2.36765018  1.76980369  2.21657542  2.46523593\n",
      "  2.58718519  1.96764627  1.66686474  1.90576224  2.66229415  2.17002694]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 3 2 2 2 3 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print((y+0.5).astype(int))              # 0.0-0.49 ~= 0, 0.50-0.99 ~= 1\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.86813781 -0.88790178 -0.72559091 -0.53643517 -0.75084844 -0.59966401\n",
      " -0.4251012  -0.75124993 -0.51946298 -0.85389706 -0.96606469 -0.51707268\n",
      " -0.8815449  -0.693575   -1.39768303 -0.80539045 -0.88873545 -0.79354\n",
      " -0.95346058 -0.61226812 -0.93053299 -0.57400499 -0.71610109 -0.50021016\n",
      " -0.3002691  -0.82432076 -0.52978646 -0.87682465 -0.98542718 -0.50878733\n",
      " -0.6260767  -0.9258731  -0.73341441 -0.93761388 -0.77929925 -1.04072285\n",
      " -1.26422445 -0.74449155 -0.55539617 -0.83220462  0.76473197  1.18052224\n",
      "  1.02848552  1.07156753  1.02649671  1.4526708   1.51694513  0.86396194\n",
      "  0.83268107  1.46210025  0.78220427  1.29582279  0.40666596  1.38432021\n",
      "  0.91954944  0.75445781  1.75549045  0.82251657  0.97908489  0.84181871\n",
      "  2.02589271  0.76751272  1.29620565  1.19878993  0.77778689  0.79907783\n",
      "  0.85357053  1.37552371  1.395337    0.43352944  0.81417087  0.66730521\n",
      "  0.82717647  1.83087261  1.91739984  1.65160817  1.04585919  0.7130014\n",
      "  1.3172234   1.14423687  3.12780755  2.21657542  2.00050688  2.17121278\n",
      "  2.488565    2.10160842  2.28969557  1.86754083  1.84659102  2.58048717\n",
      "  1.90616372  1.87538296  1.95429953  2.22719072  2.62589912  2.35544756\n",
      "  1.9733702   2.45819677  2.24131422  1.50233358  2.23974552  2.34488157\n",
      "  1.94565443  1.59266842  2.28879397  1.84069597  1.63768993  1.86358183\n",
      "  2.27771683  1.4742953   1.68031355  1.93028819  2.35231463  1.54974539\n",
      "  1.92572692  1.80851004  2.80047298  2.09065957  1.87226867  1.83741165]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 2 1 1 1 1 1 0 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 0 1 1 1 2\n",
      " 2 2 1 1 1 1 3 2 2 2 2 2 2 2 2 3 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2\n",
      " 2 2 2 2 2 3 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(yy)\n",
    "print((yy+0.5).astype(int))              # 0.0-0.49 ~= 0, 0.50-0.99 ~= 1\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
