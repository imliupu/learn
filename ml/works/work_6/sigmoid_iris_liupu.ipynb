{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writen by liupu -- 2019.4.13\n",
    "# Need to install numpy, sklearn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "data=iris.data      #data_x\n",
    "target=iris.target  #data_y\n",
    "labels=iris.feature_names #feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "(150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "(150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(data.shape)\n",
    "print(data[:10])\n",
    "print(target.shape)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.append(np.append(target[:40], target[50:90]), target[100:140])\n",
    "train_x = np.append(np.append(data[:40,], data[50:90,], axis=0), data[100:140,], axis=0)\n",
    "test_y = np.append(np.append(target[40:50], target[90:100]), target[140:150])\n",
    "test_x = np.append(np.append(data[40:50], data[90:100], axis=0), data[140:150], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (120,)\n",
      "(30, 4) (30,)\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self):\n",
    "        self._w = None                 # _w = [ feature_num, bias ]\n",
    "        self._x = None\n",
    "        self._y = None\n",
    "        self._feature_num = 0\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1+np.exp(-x))\n",
    "    \n",
    "    def get_gradient(self, x, y):\n",
    "        xTw = np.matmul(x.T, self._w)\n",
    "        sig = self.sigmoid(xTw)\n",
    "        return sig * (sig-1) * (y-sig) * x\n",
    "    \n",
    "    def fit(self, x, y, optimizer=\"square\", learning_rate=0.001, epoch=1, log=True):\n",
    "        assert len(x.shape) == 2\n",
    "        assert len(y.shape) == 1\n",
    "        assert x.shape[0] == y.shape[0]\n",
    "        self._feature_num = x.shape[1]\n",
    "        if self._w == None:\n",
    "            self._w = np.random.normal(0.1, 1, size=self._feature_num+1)    # _w = [ feature_num, bias ], ^y = Xw\n",
    "        self._x = np.append(x, np.tile(1, [x.shape[0],1]), axis=1)\n",
    "        self._y = y\n",
    "        if optimizer == \"sgd\":\n",
    "            if log == True:\n",
    "                print(\"Log is working on...\")\n",
    "                print(\"The learning_rate is now %f. Start...\"%learning_rate)\n",
    "            for j in range(epoch):\n",
    "                print(\"********************* Epoch %d **********************\"%j)\n",
    "                for i, item in enumerate(self._x):\n",
    "                    loss = 1/2*(self._y[i]-np.matmul(item.T, self._w))**2\n",
    "                    gradient = self.get_gradient(item, self._y[i])\n",
    "                    self._w -= learning_rate * gradient\n",
    "                    if i:\n",
    "                        print(\"Iter : %d, Loss : %f\"%(i+1,loss))\n",
    "            \n",
    "    \n",
    "    def predict(self, x):\n",
    "        assert len(x.shape) == 2\n",
    "        assert self._feature_num == x.shape[1]\n",
    "        expand_x = np.append(x, np.tile(1, [x.shape[0],1]), axis=1)\n",
    "        return np.matmul(expand_x, self._w)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log is working on...\n",
      "The learning_rate is now 0.001000. Start...\n",
      "********************* Epoch 0 **********************\n",
      "Iter : 2, Loss : 4.607177\n",
      "Iter : 3, Loss : 5.080697\n",
      "Iter : 4, Loss : 3.600822\n",
      "Iter : 5, Loss : 5.944798\n",
      "Iter : 6, Loss : 5.667148\n",
      "Iter : 7, Loss : 4.630696\n",
      "Iter : 8, Loss : 4.940425\n",
      "Iter : 9, Loss : 3.383113\n",
      "Iter : 10, Loss : 4.172129\n",
      "Iter : 11, Loss : 6.490961\n",
      "Iter : 12, Loss : 3.931700\n",
      "Iter : 13, Loss : 4.320335\n",
      "Iter : 14, Loss : 4.897478\n",
      "Iter : 15, Loss : 10.669149\n",
      "Iter : 16, Loss : 8.938457\n",
      "Iter : 17, Loss : 8.379778\n",
      "Iter : 18, Loss : 5.960245\n",
      "Iter : 19, Loss : 6.139152\n",
      "Iter : 20, Loss : 5.901392\n",
      "Iter : 21, Loss : 4.642438\n",
      "Iter : 22, Loss : 5.716567\n",
      "Iter : 23, Loss : 7.509892\n",
      "Iter : 24, Loss : 3.876936\n",
      "Iter : 25, Loss : 2.486368\n",
      "Iter : 26, Loss : 3.653532\n",
      "Iter : 27, Loss : 4.325479\n",
      "Iter : 28, Loss : 5.500212\n",
      "Iter : 29, Loss : 5.932040\n",
      "Iter : 30, Loss : 3.358913\n",
      "Iter : 31, Loss : 3.394834\n",
      "Iter : 32, Loss : 5.815024\n",
      "Iter : 33, Loss : 6.638843\n",
      "Iter : 34, Loss : 8.448471\n",
      "Iter : 35, Loss : 4.089139\n",
      "Iter : 36, Loss : 6.288306\n",
      "Iter : 37, Loss : 7.582776\n",
      "Iter : 38, Loss : 5.514469\n",
      "Iter : 39, Loss : 3.937429\n",
      "Iter : 40, Loss : 5.023067\n",
      "Iter : 41, Loss : 2.999350\n",
      "Iter : 42, Loss : 3.119451\n",
      "Iter : 43, Loss : 4.278192\n",
      "Iter : 44, Loss : 3.734633\n",
      "Iter : 45, Loss : 3.962147\n",
      "Iter : 46, Loss : 5.180322\n",
      "Iter : 47, Loss : 4.040765\n",
      "Iter : 48, Loss : 1.636352\n",
      "Iter : 49, Loss : 3.558048\n",
      "Iter : 50, Loss : 3.112003\n",
      "Iter : 51, Loss : 2.685066\n",
      "Iter : 52, Loss : 2.753048\n",
      "Iter : 53, Loss : 2.837286\n",
      "Iter : 54, Loss : 5.037629\n",
      "Iter : 55, Loss : 1.128665\n",
      "Iter : 56, Loss : 2.091111\n",
      "Iter : 57, Loss : 4.755377\n",
      "Iter : 58, Loss : 2.861743\n",
      "Iter : 59, Loss : 4.761197\n",
      "Iter : 60, Loss : 2.566447\n",
      "Iter : 61, Loss : 5.301431\n",
      "Iter : 62, Loss : 1.771312\n",
      "Iter : 63, Loss : 6.303219\n",
      "Iter : 64, Loss : 5.026680\n",
      "Iter : 65, Loss : 2.284459\n",
      "Iter : 66, Loss : 2.204332\n",
      "Iter : 67, Loss : 3.906457\n",
      "Iter : 68, Loss : 4.794473\n",
      "Iter : 69, Loss : 3.805370\n",
      "Iter : 70, Loss : 0.888778\n",
      "Iter : 71, Loss : 2.287401\n",
      "Iter : 72, Loss : 1.907686\n",
      "Iter : 73, Loss : 1.811541\n",
      "Iter : 74, Loss : 7.737611\n",
      "Iter : 75, Loss : 4.825452\n",
      "Iter : 76, Loss : 2.908438\n",
      "Iter : 77, Loss : 2.941487\n",
      "Iter : 78, Loss : 3.487507\n",
      "Iter : 79, Loss : 2.423648\n",
      "Iter : 80, Loss : 2.820884\n",
      "Iter : 81, Loss : 17.431704\n",
      "Iter : 82, Loss : 12.546607\n",
      "Iter : 83, Loss : 14.074303\n",
      "Iter : 84, Loss : 14.742206\n",
      "Iter : 85, Loss : 15.439841\n",
      "Iter : 86, Loss : 19.208595\n",
      "Iter : 87, Loss : 11.013350\n",
      "Iter : 88, Loss : 17.638814\n",
      "Iter : 89, Loss : 16.267406\n",
      "Iter : 90, Loss : 13.437448\n",
      "Iter : 91, Loss : 8.550003\n",
      "Iter : 92, Loss : 11.822626\n",
      "Iter : 93, Loss : 11.181116\n",
      "Iter : 94, Loss : 12.188867\n",
      "Iter : 95, Loss : 11.692236\n",
      "Iter : 96, Loss : 10.171847\n",
      "Iter : 97, Loss : 12.206948\n",
      "Iter : 98, Loss : 16.367398\n",
      "Iter : 99, Loss : 22.975930\n",
      "Iter : 100, Loss : 11.913874\n",
      "Iter : 101, Loss : 11.654616\n",
      "Iter : 102, Loss : 10.593575\n",
      "Iter : 103, Loss : 19.736571\n",
      "Iter : 104, Loss : 8.518760\n",
      "Iter : 105, Loss : 11.999017\n",
      "Iter : 106, Loss : 13.181067\n",
      "Iter : 107, Loss : 7.739206\n",
      "Iter : 108, Loss : 8.247588\n",
      "Iter : 109, Loss : 13.480617\n",
      "Iter : 110, Loss : 11.768396\n",
      "Iter : 111, Loss : 14.214234\n",
      "Iter : 112, Loss : 11.953584\n",
      "Iter : 113, Loss : 13.279875\n",
      "Iter : 114, Loss : 9.511716\n",
      "Iter : 115, Loss : 15.364420\n",
      "Iter : 116, Loss : 12.046754\n",
      "Iter : 117, Loss : 11.662353\n",
      "Iter : 118, Loss : 11.430164\n",
      "Iter : 119, Loss : 7.473716\n",
      "Iter : 120, Loss : 8.657766\n",
      "********************* Epoch 1 **********************\n",
      "Iter : 2, Loss : 5.711370\n",
      "Iter : 3, Loss : 6.206706\n",
      "Iter : 4, Loss : 4.562188\n",
      "Iter : 5, Loss : 7.257376\n",
      "Iter : 6, Loss : 7.095066\n",
      "Iter : 7, Loss : 5.728600\n",
      "Iter : 8, Loss : 6.146637\n",
      "Iter : 9, Loss : 4.272746\n",
      "Iter : 10, Loss : 5.250490\n",
      "Iter : 11, Loss : 7.966073\n",
      "Iter : 12, Loss : 5.003312\n",
      "Iter : 13, Loss : 5.386508\n",
      "Iter : 14, Loss : 5.910670\n",
      "Iter : 15, Loss : 12.612221\n",
      "Iter : 16, Loss : 10.806008\n",
      "Iter : 17, Loss : 10.050323\n",
      "Iter : 18, Loss : 7.307904\n",
      "Iter : 19, Loss : 7.683730\n",
      "Iter : 20, Loss : 7.283055\n",
      "Iter : 21, Loss : 5.919627\n",
      "Iter : 22, Loss : 7.078538\n",
      "Iter : 23, Loss : 8.862055\n",
      "Iter : 24, Loss : 5.016565\n",
      "Iter : 25, Loss : 3.393581\n",
      "Iter : 26, Loss : 4.708911\n",
      "Iter : 27, Loss : 5.505438\n",
      "Iter : 28, Loss : 6.841457\n",
      "Iter : 29, Loss : 7.301125\n",
      "Iter : 30, Loss : 4.349248\n",
      "Iter : 31, Loss : 4.399634\n",
      "Iter : 32, Loss : 7.237751\n",
      "Iter : 33, Loss : 8.158780\n",
      "Iter : 34, Loss : 10.216293\n",
      "Iter : 35, Loss : 5.192920\n",
      "Iter : 36, Loss : 7.624126\n",
      "Iter : 37, Loss : 9.188399\n",
      "Iter : 38, Loss : 6.808013\n",
      "Iter : 39, Loss : 4.920412\n",
      "Iter : 40, Loss : 6.301111\n",
      "Iter : 41, Loss : 1.696036\n",
      "Iter : 42, Loss : 1.849815\n",
      "Iter : 43, Loss : 2.671738\n",
      "Iter : 44, Loss : 2.505554\n",
      "Iter : 45, Loss : 2.495646\n",
      "Iter : 46, Loss : 3.593645\n",
      "Iter : 47, Loss : 2.533829\n",
      "Iter : 48, Loss : 0.933425\n",
      "Iter : 49, Loss : 2.154332\n",
      "Iter : 50, Loss : 2.000094\n",
      "Iter : 51, Loss : 1.744375\n",
      "Iter : 52, Loss : 1.612256\n",
      "Iter : 53, Loss : 1.725030\n",
      "Iter : 54, Loss : 3.366046\n",
      "Iter : 55, Loss : 0.491107\n",
      "Iter : 56, Loss : 1.040540\n",
      "Iter : 57, Loss : 3.206513\n",
      "Iter : 58, Loss : 1.727004\n",
      "Iter : 59, Loss : 3.171652\n",
      "Iter : 60, Loss : 1.530443\n",
      "Iter : 61, Loss : 3.544649\n",
      "Iter : 62, Loss : 0.877228\n",
      "Iter : 63, Loss : 4.351776\n",
      "Iter : 64, Loss : 3.338069\n",
      "Iter : 65, Loss : 1.194877\n",
      "Iter : 66, Loss : 1.109480\n",
      "Iter : 67, Loss : 2.338141\n",
      "Iter : 68, Loss : 2.999549\n",
      "Iter : 69, Loss : 2.354564\n",
      "Iter : 70, Loss : 0.330921\n",
      "Iter : 71, Loss : 1.314652\n",
      "Iter : 72, Loss : 1.038351\n",
      "Iter : 73, Loss : 0.921965\n",
      "Iter : 74, Loss : 5.519622\n",
      "Iter : 75, Loss : 3.235494\n",
      "Iter : 76, Loss : 1.630055\n",
      "Iter : 77, Loss : 1.586696\n",
      "Iter : 78, Loss : 2.100563\n",
      "Iter : 79, Loss : 1.347334\n",
      "Iter : 80, Loss : 1.684161\n",
      "Iter : 81, Loss : 13.526134\n",
      "Iter : 82, Loss : 9.635223\n",
      "Iter : 83, Loss : 10.437512\n",
      "Iter : 84, Loss : 11.279644\n",
      "Iter : 85, Loss : 11.735704\n",
      "Iter : 86, Loss : 14.519854\n",
      "Iter : 87, Loss : 8.555433\n",
      "Iter : 88, Loss : 13.301881\n",
      "Iter : 89, Loss : 12.414294\n",
      "Iter : 90, Loss : 9.596207\n",
      "Iter : 91, Loss : 5.867665\n",
      "Iter : 92, Loss : 8.631504\n",
      "Iter : 93, Loss : 7.889618\n",
      "Iter : 94, Loss : 9.130093\n",
      "Iter : 95, Loss : 8.579254\n",
      "Iter : 96, Loss : 7.062593\n",
      "Iter : 97, Loss : 8.730403\n",
      "Iter : 98, Loss : 11.497342\n",
      "Iter : 99, Loss : 17.200988\n",
      "Iter : 100, Loss : 8.753623\n",
      "Iter : 101, Loss : 7.985868\n",
      "Iter : 102, Loss : 7.594814\n",
      "Iter : 103, Loss : 14.319199\n",
      "Iter : 104, Loss : 5.697863\n",
      "Iter : 105, Loss : 8.204927\n",
      "Iter : 106, Loss : 8.984010\n",
      "Iter : 107, Loss : 5.016097\n",
      "Iter : 108, Loss : 5.384941\n",
      "Iter : 109, Loss : 9.450768\n",
      "Iter : 110, Loss : 7.763019\n",
      "Iter : 111, Loss : 9.596342\n",
      "Iter : 112, Loss : 7.405739\n",
      "Iter : 113, Loss : 9.117550\n",
      "Iter : 114, Loss : 6.193372\n",
      "Iter : 115, Loss : 10.978398\n",
      "Iter : 116, Loss : 7.512324\n",
      "Iter : 117, Loss : 7.593459\n",
      "Iter : 118, Loss : 7.446902\n",
      "Iter : 119, Loss : 4.524063\n",
      "Iter : 120, Loss : 5.067505\n",
      "********************* Epoch 2 **********************\n",
      "Iter : 2, Loss : 7.757197\n",
      "Iter : 3, Loss : 8.276508\n",
      "Iter : 4, Loss : 6.364379\n",
      "Iter : 5, Loss : 9.668299\n",
      "Iter : 6, Loss : 9.753149\n",
      "Iter : 7, Loss : 7.758352\n",
      "Iter : 8, Loss : 8.382230\n",
      "Iter : 9, Loss : 5.934179\n",
      "Iter : 10, Loss : 7.259711\n",
      "Iter : 11, Loss : 10.676635\n",
      "Iter : 12, Loss : 7.011495\n",
      "Iter : 13, Loss : 7.360387\n",
      "Iter : 14, Loss : 7.753331\n",
      "Iter : 15, Loss : 16.104724\n",
      "Iter : 16, Loss : 14.205430\n",
      "Iter : 17, Loss : 13.075861\n",
      "Iter : 18, Loss : 9.777566\n",
      "Iter : 19, Loss : 10.545321\n",
      "Iter : 20, Loss : 9.823229\n",
      "Iter : 21, Loss : 8.307695\n",
      "Iter : 22, Loss : 9.584359\n",
      "Iter : 23, Loss : 11.284806\n",
      "Iter : 24, Loss : 7.161815\n",
      "Iter : 25, Loss : 5.151147\n",
      "Iter : 26, Loss : 6.689157\n",
      "Iter : 27, Loss : 7.704122\n",
      "Iter : 28, Loss : 9.308612\n",
      "Iter : 29, Loss : 9.803578\n",
      "Iter : 30, Loss : 6.210008\n",
      "Iter : 31, Loss : 6.287202\n",
      "Iter : 32, Loss : 9.850269\n",
      "Iter : 33, Loss : 10.932684\n",
      "Iter : 34, Loss : 13.412081\n",
      "Iter : 35, Loss : 7.240547\n",
      "Iter : 36, Loss : 10.038811\n",
      "Iter : 37, Loss : 12.089130\n",
      "Iter : 38, Loss : 9.170148\n",
      "Iter : 39, Loss : 6.726018\n",
      "Iter : 40, Loss : 8.652782\n",
      "Iter : 41, Loss : 0.381349\n",
      "Iter : 42, Loss : 0.513118\n",
      "Iter : 43, Loss : 0.903149\n",
      "Iter : 44, Loss : 1.068792\n",
      "Iter : 45, Loss : 0.876034\n",
      "Iter : 46, Loss : 1.694376\n",
      "Iter : 47, Loss : 0.881385\n",
      "Iter : 48, Loss : 0.229579\n",
      "Iter : 49, Loss : 0.669761\n",
      "Iter : 50, Loss : 0.763312\n",
      "Iter : 51, Loss : 0.690771\n",
      "Iter : 52, Loss : 0.449925\n",
      "Iter : 53, Loss : 0.555747\n",
      "Iter : 54, Loss : 1.462788\n",
      "Iter : 55, Loss : 0.022351\n",
      "Iter : 56, Loss : 0.138364\n",
      "Iter : 57, Loss : 1.440882\n",
      "Iter : 58, Loss : 0.553019\n",
      "Iter : 59, Loss : 1.386322\n",
      "Iter : 60, Loss : 0.474243\n",
      "Iter : 61, Loss : 1.572077\n",
      "Iter : 62, Loss : 0.120105\n",
      "Iter : 63, Loss : 2.112933\n",
      "Iter : 64, Loss : 1.460775\n",
      "Iter : 65, Loss : 0.221385\n",
      "Iter : 66, Loss : 0.171604\n",
      "Iter : 67, Loss : 0.756595\n",
      "Iter : 68, Loss : 1.124131\n",
      "Iter : 69, Loss : 0.856125\n",
      "Iter : 70, Loss : 0.001530\n",
      "Iter : 71, Loss : 0.376455\n",
      "Iter : 72, Loss : 0.242931\n",
      "Iter : 73, Loss : 0.161096\n",
      "Iter : 74, Loss : 2.977328\n",
      "Iter : 75, Loss : 1.497131\n",
      "Iter : 76, Loss : 0.432812\n",
      "Iter : 77, Loss : 0.366639\n",
      "Iter : 78, Loss : 0.726512\n",
      "Iter : 79, Loss : 0.356290\n",
      "Iter : 80, Loss : 0.572218\n",
      "Iter : 81, Loss : 8.849732\n",
      "Iter : 82, Loss : 6.162272\n",
      "Iter : 83, Loss : 6.197236\n",
      "Iter : 84, Loss : 7.130633\n",
      "Iter : 85, Loss : 7.301882\n",
      "Iter : 86, Loss : 8.908678\n",
      "Iter : 87, Loss : 5.538457\n",
      "Iter : 88, Loss : 8.087315\n",
      "Iter : 89, Loss : 7.718234\n",
      "Iter : 90, Loss : 5.122903\n",
      "Iter : 91, Loss : 2.826885\n",
      "Iter : 92, Loss : 4.848570\n",
      "Iter : 93, Loss : 4.079643\n",
      "Iter : 94, Loss : 5.418110\n",
      "Iter : 95, Loss : 4.850401\n",
      "Iter : 96, Loss : 3.487549\n",
      "Iter : 97, Loss : 4.640831\n",
      "Iter : 98, Loss : 5.833356\n",
      "Iter : 99, Loss : 10.100597\n",
      "Iter : 100, Loss : 4.905902\n",
      "Iter : 101, Loss : 3.749388\n",
      "Iter : 102, Loss : 3.998100\n",
      "Iter : 103, Loss : 7.758752\n",
      "Iter : 104, Loss : 2.480499\n",
      "Iter : 105, Loss : 3.813414\n",
      "Iter : 106, Loss : 4.130962\n",
      "Iter : 107, Loss : 1.988044\n",
      "Iter : 108, Loss : 2.199326\n",
      "Iter : 109, Loss : 4.718501\n",
      "Iter : 110, Loss : 3.274639\n",
      "Iter : 111, Loss : 4.316962\n",
      "Iter : 112, Loss : 2.555297\n",
      "Iter : 113, Loss : 4.277403\n",
      "Iter : 114, Loss : 2.491686\n",
      "Iter : 115, Loss : 5.712125\n",
      "Iter : 116, Loss : 2.637825\n",
      "Iter : 117, Loss : 3.053256\n",
      "Iter : 118, Loss : 3.000076\n",
      "Iter : 119, Loss : 1.438494\n",
      "Iter : 120, Loss : 1.451534\n",
      "********************* Epoch 3 **********************\n",
      "Iter : 2, Loss : 11.400242\n",
      "Iter : 3, Loss : 11.926101\n",
      "Iter : 4, Loss : 9.616597\n",
      "Iter : 5, Loss : 13.914238\n",
      "Iter : 6, Loss : 14.510642\n",
      "Iter : 7, Loss : 11.361622\n",
      "Iter : 8, Loss : 12.363037\n",
      "Iter : 9, Loss : 8.919340\n",
      "Iter : 10, Loss : 10.859541\n",
      "Iter : 11, Loss : 15.453292\n",
      "Iter : 12, Loss : 10.632461\n",
      "Iter : 13, Loss : 10.870659\n",
      "Iter : 14, Loss : 10.959536\n",
      "Iter : 15, Loss : 22.092669\n",
      "Iter : 16, Loss : 20.126478\n",
      "Iter : 17, Loss : 18.314746\n",
      "Iter : 18, Loss : 14.116680\n",
      "Iter : 19, Loss : 15.638683\n",
      "Iter : 20, Loss : 14.302587\n",
      "Iter : 21, Loss : 12.603831\n",
      "Iter : 22, Loss : 14.008259\n",
      "Iter : 23, Loss : 15.422501\n",
      "Iter : 24, Loss : 11.051507\n",
      "Iter : 25, Loss : 8.435225\n",
      "Iter : 26, Loss : 10.265080\n",
      "Iter : 27, Loss : 11.642979\n",
      "Iter : 28, Loss : 13.661885\n",
      "Iter : 29, Loss : 14.186697\n",
      "Iter : 30, Loss : 9.573639\n",
      "Iter : 31, Loss : 9.698659\n",
      "Iter : 32, Loss : 14.452340\n",
      "Iter : 33, Loss : 15.778166\n",
      "Iter : 34, Loss : 18.932241\n",
      "Iter : 35, Loss : 10.889575\n",
      "Iter : 36, Loss : 14.212518\n",
      "Iter : 37, Loss : 17.099485\n",
      "Iter : 38, Loss : 13.300881\n",
      "Iter : 39, Loss : 9.906817\n",
      "Iter : 40, Loss : 12.803705\n",
      "Iter : 41, Loss : 0.156111\n",
      "Iter : 42, Loss : 0.054381\n",
      "Iter : 43, Loss : 0.003067\n",
      "Iter : 44, Loss : 0.053777\n",
      "Iter : 45, Loss : 0.000000\n",
      "Iter : 46, Loss : 0.195515\n",
      "Iter : 47, Loss : 0.000001\n",
      "Iter : 48, Loss : 0.047275\n",
      "Iter : 49, Loss : 0.012165\n",
      "Iter : 50, Loss : 0.010792\n",
      "Iter : 51, Loss : 0.018600\n",
      "Iter : 52, Loss : 0.031455\n",
      "Iter : 53, Loss : 0.003171\n",
      "Iter : 54, Loss : 0.107990\n",
      "Iter : 55, Loss : 0.386728\n",
      "Iter : 56, Loss : 0.287583\n",
      "Iter : 57, Loss : 0.138524\n",
      "Iter : 58, Loss : 0.002696\n",
      "Iter : 59, Loss : 0.114102\n",
      "Iter : 60, Loss : 0.004871\n",
      "Iter : 61, Loss : 0.148348\n",
      "Iter : 62, Loss : 0.213908\n",
      "Iter : 63, Loss : 0.342404\n",
      "Iter : 64, Loss : 0.132824\n",
      "Iter : 65, Loss : 0.139810\n",
      "Iter : 66, Loss : 0.204170\n",
      "Iter : 67, Loss : 0.000561\n",
      "Iter : 68, Loss : 0.023868\n",
      "Iter : 69, Loss : 0.012000\n",
      "Iter : 70, Loss : 0.454827\n",
      "Iter : 71, Loss : 0.009509\n",
      "Iter : 72, Loss : 0.043153\n",
      "Iter : 73, Loss : 0.117230\n",
      "Iter : 74, Loss : 0.799131\n",
      "Iter : 75, Loss : 0.211350\n",
      "Iter : 76, Loss : 0.025437\n",
      "Iter : 77, Loss : 0.065434\n",
      "Iter : 78, Loss : 0.004668\n",
      "Iter : 79, Loss : 0.019750\n",
      "Iter : 80, Loss : 0.002462\n",
      "Iter : 81, Loss : 4.232919\n",
      "Iter : 82, Loss : 2.783342\n",
      "Iter : 83, Loss : 2.315567\n",
      "Iter : 84, Loss : 3.154851\n",
      "Iter : 85, Loss : 3.105293\n",
      "Iter : 86, Loss : 3.656505\n",
      "Iter : 87, Loss : 2.583226\n",
      "Iter : 88, Loss : 3.236371\n",
      "Iter : 89, Loss : 3.263948\n",
      "Iter : 90, Loss : 1.379209\n",
      "Iter : 91, Loss : 0.529162\n",
      "Iter : 92, Loss : 1.611195\n",
      "Iter : 93, Loss : 1.060149\n",
      "Iter : 94, Loss : 2.159103\n",
      "Iter : 95, Loss : 1.711628\n",
      "Iter : 96, Loss : 0.817319\n",
      "Iter : 97, Loss : 1.424551\n",
      "Iter : 98, Loss : 1.581227\n",
      "Iter : 99, Loss : 4.157439\n",
      "Iter : 100, Loss : 1.781295\n",
      "Iter : 101, Loss : 0.794476\n",
      "Iter : 102, Loss : 1.269499\n",
      "Iter : 103, Loss : 2.705475\n",
      "Iter : 104, Loss : 0.418678\n",
      "Iter : 105, Loss : 0.857375\n",
      "Iter : 106, Loss : 0.929365\n",
      "Iter : 107, Loss : 0.257466\n",
      "Iter : 108, Loss : 0.340811\n",
      "Iter : 109, Loss : 1.480028\n",
      "Iter : 110, Loss : 0.618580\n",
      "Iter : 111, Loss : 1.060243\n",
      "Iter : 112, Loss : 0.215438\n",
      "Iter : 113, Loss : 1.281348\n",
      "Iter : 114, Loss : 0.482746\n",
      "Iter : 115, Loss : 2.269511\n",
      "Iter : 116, Loss : 0.314547\n",
      "Iter : 117, Loss : 0.656303\n",
      "Iter : 118, Loss : 0.676183\n",
      "Iter : 119, Loss : 0.135045\n",
      "Iter : 120, Loss : 0.076463\n",
      "********************* Epoch 4 **********************\n",
      "Iter : 2, Loss : 15.129550\n",
      "Iter : 3, Loss : 15.630871\n",
      "Iter : 4, Loss : 12.981537\n",
      "Iter : 5, Loss : 18.219534\n",
      "Iter : 6, Loss : 19.400318\n",
      "Iter : 7, Loss : 15.040266\n",
      "Iter : 8, Loss : 16.437759\n",
      "Iter : 9, Loss : 11.997797\n",
      "Iter : 10, Loss : 14.563239\n",
      "Iter : 11, Loss : 20.300923\n",
      "Iter : 12, Loss : 14.376617\n",
      "Iter : 13, Loss : 14.460906\n",
      "Iter : 14, Loss : 14.178929\n",
      "Iter : 15, Loss : 28.028834\n",
      "Iter : 16, Loss : 26.076658\n",
      "Iter : 17, Loss : 23.554165\n",
      "Iter : 18, Loss : 18.510792\n",
      "Iter : 19, Loss : 20.852386\n",
      "Iter : 20, Loss : 18.852215\n",
      "Iter : 21, Loss : 17.040112\n",
      "Iter : 22, Loss : 18.507023\n",
      "Iter : 23, Loss : 19.511697\n",
      "Iter : 24, Loss : 15.094108\n",
      "Iter : 25, Loss : 11.925792\n",
      "Iter : 26, Loss : 13.969477\n",
      "Iter : 27, Loss : 15.697368\n",
      "Iter : 28, Loss : 18.087826\n",
      "Iter : 29, Loss : 18.616468\n",
      "Iter : 30, Loss : 13.060433\n",
      "Iter : 31, Loss : 13.234858\n",
      "Iter : 32, Loss : 19.126760\n",
      "Iter : 33, Loss : 20.662570\n",
      "Iter : 34, Loss : 24.445463\n",
      "Iter : 35, Loss : 14.630868\n",
      "Iter : 36, Loss : 18.385609\n",
      "Iter : 37, Loss : 22.106258\n",
      "Iter : 38, Loss : 17.470254\n",
      "Iter : 39, Loss : 13.137849\n",
      "Iter : 40, Loss : 17.026930\n",
      "Iter : 41, Loss : 1.619444\n",
      "Iter : 42, Loss : 1.122212\n",
      "Iter : 43, Loss : 0.871426\n",
      "Iter : 44, Loss : 0.221367\n",
      "Iter : 45, Loss : 0.673571\n",
      "Iter : 46, Loss : 0.097784\n",
      "Iter : 47, Loss : 0.680224\n",
      "Iter : 48, Loss : 0.687106\n",
      "Iter : 49, Loss : 0.859880\n",
      "Iter : 50, Loss : 0.331108\n",
      "Iter : 51, Loss : 0.227867\n",
      "Iter : 52, Loss : 0.859345\n",
      "Iter : 53, Loss : 0.588142\n",
      "Iter : 54, Loss : 0.206117\n",
      "Iter : 55, Loss : 1.705414\n",
      "Iter : 56, Loss : 1.805090\n",
      "Iter : 57, Loss : 0.134735\n",
      "Iter : 58, Loss : 0.579092\n",
      "Iter : 59, Loss : 0.170400\n",
      "Iter : 60, Loss : 0.557759\n",
      "Iter : 61, Loss : 0.153933\n",
      "Iter : 62, Loss : 1.404246\n",
      "Iter : 63, Loss : 0.037443\n",
      "Iter : 64, Loss : 0.151729\n",
      "Iter : 65, Loss : 1.269913\n",
      "Iter : 66, Loss : 1.504302\n",
      "Iter : 67, Loss : 0.682032\n",
      "Iter : 68, Loss : 0.436902\n",
      "Iter : 69, Loss : 0.391426\n",
      "Iter : 70, Loss : 1.736140\n",
      "Iter : 71, Loss : 0.547741\n",
      "Iter : 72, Loss : 0.708814\n",
      "Iter : 73, Loss : 1.034050\n",
      "Iter : 74, Loss : 0.018744\n",
      "Iter : 75, Loss : 0.053444\n",
      "Iter : 76, Loss : 0.805146\n",
      "Iter : 77, Loss : 1.072256\n",
      "Iter : 78, Loss : 0.414937\n",
      "Iter : 79, Loss : 0.658400\n",
      "Iter : 80, Loss : 0.354145\n",
      "Iter : 81, Loss : 1.483865\n",
      "Iter : 82, Loss : 0.871264\n",
      "Iter : 83, Loss : 0.434908\n",
      "Iter : 84, Loss : 0.990528\n",
      "Iter : 85, Loss : 0.909230\n",
      "Iter : 86, Loss : 1.010052\n",
      "Iter : 87, Loss : 0.978130\n",
      "Iter : 88, Loss : 0.885600\n",
      "Iter : 89, Loss : 1.049913\n",
      "Iter : 90, Loss : 0.097440\n",
      "Iter : 91, Loss : 0.000201\n",
      "Iter : 92, Loss : 0.298195\n",
      "Iter : 93, Loss : 0.074026\n",
      "Iter : 94, Loss : 0.671703\n",
      "Iter : 95, Loss : 0.409239\n",
      "Iter : 96, Loss : 0.037134\n",
      "Iter : 97, Loss : 0.239270\n",
      "Iter : 98, Loss : 0.176196\n",
      "Iter : 99, Loss : 1.520247\n",
      "Iter : 100, Loss : 0.521379\n",
      "Iter : 101, Loss : 0.029813\n",
      "Iter : 102, Loss : 0.282702\n",
      "Iter : 103, Loss : 0.763284\n",
      "Iter : 104, Loss : 0.001205\n",
      "Iter : 105, Loss : 0.062086\n",
      "Iter : 106, Loss : 0.070955\n",
      "Iter : 107, Loss : 0.005613\n",
      "Iter : 108, Loss : 0.000010\n",
      "Iter : 109, Loss : 0.359208\n",
      "Iter : 110, Loss : 0.018172\n",
      "Iter : 111, Loss : 0.133975\n",
      "Iter : 112, Loss : 0.059660\n",
      "Iter : 113, Loss : 0.298760\n",
      "Iter : 114, Loss : 0.022224\n",
      "Iter : 115, Loss : 0.924981\n",
      "Iter : 116, Loss : 0.007331\n",
      "Iter : 117, Loss : 0.058079\n",
      "Iter : 118, Loss : 0.074504\n",
      "Iter : 119, Loss : 0.017435\n",
      "Iter : 120, Loss : 0.079660\n"
     ]
    }
   ],
   "source": [
    "linear = Linear()\n",
    "linear.fit(x=train_x, y=train_y, optimizer=\"sgd\", epoch=5)\n",
    "y = linear.predict(test_x)\n",
    "yy = linear.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.59147748 5.14255612 5.6816764  6.18061763 6.01831599 5.84296151\n",
      " 6.4463269  5.75090666 6.74955044 6.27179126 1.85900025 2.55195911\n",
      " 2.81041953 2.73886319 2.37024271 2.68740516 2.63034081 3.03457297\n",
      " 3.47842539 2.71022975 1.92664549 2.90335075 1.30954458 1.63306411\n",
      " 1.93812302 2.4516964  1.87355462 2.17690862 1.88201283 1.62670704]\n",
      "[7 5 6 6 6 6 6 6 7 6 2 3 3 3 2 3 3 3 3 3 2 3 1 2 2 2 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print((y+0.5).astype(int))              # 0.0-0.49 ~= 0, 0.50-0.99 ~= 1\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.86813781 -0.88790178 -0.72559091 -0.53643517 -0.75084844 -0.59966401\n",
      " -0.4251012  -0.75124993 -0.51946298 -0.85389706 -0.96606469 -0.51707268\n",
      " -0.8815449  -0.693575   -1.39768303 -0.80539045 -0.88873545 -0.79354\n",
      " -0.95346058 -0.61226812 -0.93053299 -0.57400499 -0.71610109 -0.50021016\n",
      " -0.3002691  -0.82432076 -0.52978646 -0.87682465 -0.98542718 -0.50878733\n",
      " -0.6260767  -0.9258731  -0.73341441 -0.93761388 -0.77929925 -1.04072285\n",
      " -1.26422445 -0.74449155 -0.55539617 -0.83220462  0.76473197  1.18052224\n",
      "  1.02848552  1.07156753  1.02649671  1.4526708   1.51694513  0.86396194\n",
      "  0.83268107  1.46210025  0.78220427  1.29582279  0.40666596  1.38432021\n",
      "  0.91954944  0.75445781  1.75549045  0.82251657  0.97908489  0.84181871\n",
      "  2.02589271  0.76751272  1.29620565  1.19878993  0.77778689  0.79907783\n",
      "  0.85357053  1.37552371  1.395337    0.43352944  0.81417087  0.66730521\n",
      "  0.82717647  1.83087261  1.91739984  1.65160817  1.04585919  0.7130014\n",
      "  1.3172234   1.14423687  3.12780755  2.21657542  2.00050688  2.17121278\n",
      "  2.488565    2.10160842  2.28969557  1.86754083  1.84659102  2.58048717\n",
      "  1.90616372  1.87538296  1.95429953  2.22719072  2.62589912  2.35544756\n",
      "  1.9733702   2.45819677  2.24131422  1.50233358  2.23974552  2.34488157\n",
      "  1.94565443  1.59266842  2.28879397  1.84069597  1.63768993  1.86358183\n",
      "  2.27771683  1.4742953   1.68031355  1.93028819  2.35231463  1.54974539\n",
      "  1.92572692  1.80851004  2.80047298  2.09065957  1.87226867  1.83741165]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 2 1 1 1 1 1 0 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 0 1 1 1 2\n",
      " 2 2 1 1 1 1 3 2 2 2 2 2 2 2 2 3 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2\n",
      " 2 2 2 2 2 3 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(yy)\n",
    "print((yy+0.5).astype(int))              # 0.0-0.49 ~= 0, 0.50-0.99 ~= 1\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
